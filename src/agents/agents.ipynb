{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml): started\n",
      "  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6105 sha256=4d09e4f251ffe0ba86cd8bd18d7eba8e1d65845df4e978f9d941a903bcfb9b24\n",
      "  Stored in directory: c:\\users\\amolj\\appdata\\local\\pip\\cache\\wheels\\03\\f5\\1a\\23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-2.2.0 feedparser-6.0.11 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "%pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\personal\\llm_pocs\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.13.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml): started\n",
      "  Building wheel for wikipedia (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11787 sha256=adab7241e77cbc41b16feebf73755d972b1ce21441224e38eda5e65323ba9826\n",
      "  Stored in directory: c:\\users\\amolj\\appdata\\local\\pip\\cache\\wheels\\63\\47\\7c\\a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from weaviate.auth import Auth\n",
    "import os\n",
    "import weaviate\n",
    "\n",
    "loader = WebBaseLoader('https://docs.smith.langchain.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load_and_split(text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "            cluster_url=f'https://{os.getenv(\"WEAVIATE_URL\")}',\n",
    "            auth_credentials=Auth.api_key(os.getenv('WEAVIATE_API_KEY')),\n",
    "            headers={\n",
    "                    'X-OpenAI-Api-Key': os.getenv('OPENAI_API_KEY') # openai api key for vectorizer & generative\n",
    "                }\n",
    "        )\n",
    "\n",
    "open_ai_embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conection = WeaviateVectorStore(client=client, index_name=\"Langsmith\", text_key=\"content\", embedding=open_ai_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['249f4417-e7e2-48e2-984a-b1d5c9a18d73',\n",
       " 'e6d3355d-fd1d-43fd-a1a5-a6e27275344d',\n",
       " '426f9df7-56ae-4763-94b4-dc1baf64ec01',\n",
       " '3089a3fd-c8ba-4bf1-a617-42b4101157bf',\n",
       " 'fdedaa08-5d97-4219-aa47-3a08b477a43c']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_conection.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = db_conection.as_retriever(\n",
    "            search_type=\"mmr\",  # or \"similarity\"\n",
    "            search_kwargs={\"k\": 5, \"lambda_mult\": 0.7}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriver_tool = create_retriever_tool(retriver, 'langsmith_search', 'Search for information about the langsmith. for any questions about Langsmith you must use this tool.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Arxiv Tool\n",
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain_community.tools.arxiv import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, retriver_tool,arxiv_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "openai_llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch prompt from langsmith Hub\n",
    "from langsmith import Client\n",
    "client = Client(api_key=os.getenv('LANGSMITH_API_KEY'))\n",
    "prompt = client.pull_prompt(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(openai_llm, tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Executor\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Skip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith. Join our team!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "Get started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evals​\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineering​\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
      "\n",
      "Get started by creating your first prompt.\n",
      "Iterate on models and prompts using the Playground.\n",
      "Manage prompts programmatically in your application.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade Large Language Models (LLM) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith provides observability features, evaluation capabilities, and tools for prompt engineering to help you optimize and improve your LLM applications.\n",
      "\n",
      "Observability:\n",
      "- Analyze traces in LangSmith and configure metrics, dashboards, and alerts based on these traces.\n",
      "- Evaluate your application over production traffic to score application performance and receive human feedback on your data.\n",
      "\n",
      "Evals:\n",
      "- Use the LangSmith SDK and UI to build and run high-quality evaluations for your applications.\n",
      "- Quickly assess the performance of your application using off-the-shelf evaluators.\n",
      "- Analyze evaluation results in the LangSmith UI and compare results over time.\n",
      "- Collect human feedback on your data to enhance your application.\n",
      "\n",
      "Prompt Engineering:\n",
      "- AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides tools for prompt engineering to help you find the perfect prompt for your application.\n",
      "- Create prompts, iterate on models, and manage prompts programmatically within your application.\n",
      "\n",
      "LangSmith is designed to provide observability, evaluation, and prompt engineering capabilities to support the development and optimization of LLM applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': 'LangSmith is a platform for building production-grade Large Language Models (LLM) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith provides observability features, evaluation capabilities, and tools for prompt engineering to help you optimize and improve your LLM applications.\\n\\nObservability:\\n- Analyze traces in LangSmith and configure metrics, dashboards, and alerts based on these traces.\\n- Evaluate your application over production traffic to score application performance and receive human feedback on your data.\\n\\nEvals:\\n- Use the LangSmith SDK and UI to build and run high-quality evaluations for your applications.\\n- Quickly assess the performance of your application using off-the-shelf evaluators.\\n- Analyze evaluation results in the LangSmith UI and compare results over time.\\n- Collect human feedback on your data to enhance your application.\\n\\nPrompt Engineering:\\n- AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides tools for prompt engineering to help you find the perfect prompt for your application.\\n- Create prompts, iterate on models, and manage prompts programmatically within your application.\\n\\nLangSmith is designed to provide observability, evaluation, and prompt engineering capabilities to support the development and optimization of LLM applications.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'Tell me about Langsmith'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'attention models'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\personal\\llm_pocs\\venv\\Lib\\site-packages\\langchain_community\\utilities\\arxiv.py:105: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  ).results()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mPublished: 2017-09-19\n",
      "Title: Exploring Human-like Attention Supervision in Visual Question Answering\n",
      "Authors: Tingting Qiao, Jianfeng Dong, Duanqing Xu\n",
      "Summary: Attention mechanisms have been widely a\u001b[0m\u001b[32;1m\u001b[1;3mThe new paper on attention models is titled \"Exploring Human-like Attention Supervision in Visual Question Answering\" by Tingting Qiao, Jianfeng Dong, and Duanqing Xu. The paper explores human-like attention supervision in visual question answering.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what the new paper on attention models',\n",
       " 'output': 'The new paper on attention models is titled \"Exploring Human-like Attention Supervision in Visual Question Answering\" by Tingting Qiao, Jianfeng Dong, and Duanqing Xu. The paper explores human-like attention supervision in visual question answering.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'what the new paper on attention models'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'current champions of football'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of English football champions\n",
      "Summary: The English football champions are the winners of the top-level league in English men's football, which since the 1992–93 season has been called the P\u001b[0m\u001b[32;1m\u001b[1;3mThe current champions of English football are Manchester City.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'who is current chamipons of football',\n",
       " 'output': 'The current champions of English football are Manchester City.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'who is current chamipons of football'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
